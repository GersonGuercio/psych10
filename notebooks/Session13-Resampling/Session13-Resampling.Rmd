---
title: 'Session 13: Resampling and simulation'
output:
  html_document:
    df_print: paged
---

In this session we discuss the concept of Monte Carlo simulation and its use in statistics.  

```{r echo=FALSE,messages=FALSE}
library(ggplot2)
library(dplyr)
```

### Distribution of finishing times

Let's say that we want to simulate the distribution of how long it will take for the class to finish the quiz.  Let's pretend that we know the distribution of how long the test will take each individual, and that it is roughly normally distributed with a mean of 5 minutes and a standard deviation.  We know that this can't really be true, since it would imply that some people could finish in negative time, but we can just ignore that for the moment since in this analysis we only care about the longest time, not the shortest.

```{r}
finishTimeDf=data.frame(finishTime=rnorm(3*150,mean=5,sd=1),
                        quiz=kronecker(c(1:3),rep(1,150)))
ggplot(finishTimeDf,aes(finishTime)) + geom_histogram(bins=25) + 
  facet_grid(. ~ quiz) + xlim(0,10)
```

What we want to know is: What is the distribution of finishing times for the entire group.  That is, what is the distribution of the maximum time needed for 150 people to finish the quiz.  There is statistical theory can could let us figure this out (see https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution) but we will proceed by simulating it.  

Let's randomly draw 5000 samples of 150 quiz-takers from the normal distribution, and then record the maximum time needed by those students in each group.  To do this efficiently, we can create a function that takes a single sample, and then use the replicate() function to repeat it many times.

```{r}
set.seed(12345)
nRuns=5000
sampSize=150

sampleMax = function(sampSize=150){
  samp=rnorm(sampSize,mean=5,sd=1)
  return(max(samp))
}

maxTime=replicate(nRuns,sampleMax())
```

Now that we have computed the maximum finishing times we can plot their distribution.

```{r}
ggplot(data.frame(maxTime=maxTime),aes(maxTime)) + geom_histogram(bins=100)
mean(maxTime)
quantile(maxTime,0.99)
```
This shows that if the mean time needed to finish the exam is 5 minutes, with a standard deviation of one minute, then we need the exam time to last about 9 minutes if we want to be sure that there is sufficient time (which we define as everyone finishing 99% of the time).

### Functions

In addition to its built in functions, R allows the user to define their own functions as well.  Whenever we are doing some kind of self-contained operation, it's good to turn it into a function, because we can then re-use it more easily.

The structure of a user-defined function is as follows:

myfunction <- function(arg1, arg2, ... ){
  <R code here>
  return(object)
}

The *arguments* (arg1,arg2,...) provide the input to the function. Everything within the squiggly brackets gets executed each time the function is run.  The return() statement provides the output from the function.  

Here is the simplest possible example: This function takes no inputs, and simply returns FALSE.  We will call it naysayer:

```{r}
naysayer = function() {
  return(FALSE)
}
```

When we run that code, it doesn't do anything that we can see, but it has created the function which we can now use. 

```{r}
naysayer()
```

Here is a simple example: Let's build a function that returns the sum of two numbers.


```{r}

sumOfTwoNumbers = function(number1,number2) {
  theSum = number1 + number2
  return(theSum)
}

```

 Let's try it out:

```{r}
sumOfTwoNumbers(12,13)
```
```{r}
combineNumbers = function(number1,number2) {
 return(c(number1,number2))
}
combineNumbers(12,13)
```

Sometimes we want to give the function a "default" setting but all people to change it if necessary. That's what we did in the sampleMax() function; we set the default value of sampSize to 150, but the user can change if if they wish.  For example, say we wish to only sample 20 observations:

```{r}
sampleMax(sampSize=20)

```


### Percentiles of a normal distribution

We already know how to compute the 95th percentile of a normal distribution, but let's say that we didn't.  Could we use simulation to determine this?

Let's say that we only know how to make numbers from a uniform random distribution. Let's see what these look like:

```{r}
nSamples=100000
randomUniform = data.frame(samples=runif(nSamples))

ggplot(randomUniform,aes(samples)) + geom_histogram(bins=500) + xlab('Value')
```

Weibull example

```{r}
randomUniform = randomUniform %>% mutate(weibull=qweibull(samples,1.5,1))
ggplot(randomUniform,aes(weibull)) + geom_histogram(bins=500) + xlab('Value')

```

Now that we have a bunch of uniform random numbers, we can turn those into normally distributed random numbers using the normal quantile function qnorm():

```{r}
randomUniform = randomUniform %>% mutate(normal=qnorm(samples))
ggplot(randomUniform,aes(normal)) + geom_histogram(bins=500) + xlab('Value')

```

Now let's generate the cumulative distribution function from these data, overlaid on top of 
the theoretical normal distribution.


```{r}
normalCDF=data.frame(x=seq(min(randomUniform$normal),
                           max(randomUniform$normal),.05))
normalCDF = normalCDF %>% mutate(cdf= pnorm(x))

ggplot(randomUniform,aes(normal)) + stat_ecdf(color='red') + xlab('Value') + 
  ylab('Cumulative density') +
  geom_line(data=normalCDF,aes(x=x,y=cdf),size=1,color='black',linetype='dotted')

```


### The boostrap: simple example

```{r}
library(NHANES)

sampSize=8
set.seed(12345)
NHANES$isChild <- NHANES$Age<18
NHANES_adult=subset(NHANES,subset=!isChild & Height!='NA')
NHANES_sample=sample_n(NHANES_adult,sampSize)
NHANES_sample=subset(NHANES_sample,select=c(Height)) %>% arrange(Height)
NHANES_sample$Height
```
```{r}
bootSample = sample_n(NHANES_sample,8,replace = TRUE) %>% arrange(Height)
bootSample$Height
unique(bootSample$Height)
print('Not included in this sample')
unique(NHANES_sample$Height)[!(unique(NHANES_sample$Height) %in% unique(bootSample$Height))]
paste('sample mean:',mean(bootSample$Height))
```

Now let's do it many times and then use the means estimated from each bootstrap sample to estimate the standard error.

```{r}
nRuns=1000
bootMeanHeight = function(df,sampleSize=8){
  bootSample = sample_n(df,sampleSize,replace = TRUE)
  return(mean(bootSample$Height))
}
bootMeans = replicate(nRuns,bootMeanHeight(NHANES_adult))

ggplot(data.frame(bootMeans=bootMeans),aes(bootMeans)) + geom_histogram(binwidth=1)

print(paste('bootstrap standard error estimate:',sd(bootMeans)))
print(paste('standard error computed from population:',
            sd(NHANES_adult$Height)/sqrt(sampSize)))

```

Now get the bootstrap confidence intervals.

```{r}
bootCI=quantile(bootMeans,c(0.025,0.975))
print("boostrap confidence limits")
bootCI

#now let's compute the confidence intervals using the population mean and SD
popMean=mean(NHANES_adult$Height)
popSD=sd(NHANES_adult$Height)

popCI = c("2.5%" = popMean - 1.96*(popSD/sqrt(sampSize)),
          "97.5%"=popMean + 1.96*(popSD/sqrt(sampSize))) 

print("confidence limits based on population")

popCI
```

### Replicate

The replicate() function is very useful for simulations, since it can do the same thing repeatedly.

```{r}
output = replicate(6,rnorm(1))
length(output)
output
```

### The bootstrap: NHANES

Let's say that we want to generate confidence intervals for a statistic that we are computing on our data, but we might not know how to compute them directly.  We can use resampling to do this, via a method known as the "bootstrap", invented by Brad Efron of the Stanford Statistics Department.

The idea behind the bootstrap is that we resample observations from our sample in order to estimate the variability of the statistic that we are computing. Let's say that we want to compute confidence intervals for the trimmed mean (which we will learn about later - it's basically the mean computed after removing a particular fraction of the most extreme .  Our data are height measurements from 200 people sampled from the NHANES dataset.

```{r}
library(NHANES)

sampSize=200

NHANES$isChild <- NHANES$Age<18
NHANES_adult=subset(NHANES,subset=!isChild & Height!='NA')
NHANES_sample=sample_n(NHANES_adult,sampSize)
NHANES_sample=subset(NHANES_sample,select=c(Height,Gender,SleepTrouble))

```

To generate a bootstrap estimate of the confidence interval for the trimmed mean, we need to perform a number of resamples from our sample of interest.  We sample "with replacement,", meaning that once an individual is selected they get stuck back into the pool and could get selected again.

Let's start by creating one such sample, and look at its characteristics.

```{r}
resamp=sample(NHANES_sample$Height,sampSize,replace=TRUE)
print(paste('original data includes',length(unique(NHANES_sample$Height)),'unique values'))
print(paste('resampled data includes',length(unique(resamp)),'unique values'))

ggplot(NHANES_sample,aes(Height,color='black')) + geom_freqpoly(bins=50) +
  geom_freqpoly(data=data.frame(resamp=resamp),aes(resamp,color='blue'),bins=50) +
  scale_colour_manual(name='dataset',values=c('black'='black','blue'='blue'),labels=c('black'='original','blue'='resample'))
```

What you can see is that only a subset of original data points show up in the resampled dataset, which means that some subjects were included more than once in the resampled dataset.

Now let's create a bunch of these and compute the mean and trimmed mean on each.
```{r}
nResamples=5000

resampleTrimmedMeans=array(NA,nResamples)
resampleMeans=array(NA,nResamples)

for (i in 1:nResamples){
  resamp=sample(NHANES_sample$Height,sampSize,replace=TRUE)
  resampleTrimmedMeans[i]=mean(resamp,trim=0.1)
  resampleMeans[i]=mean(resamp)
}



```

First let's look at the confidence interval that is estimated for the mean, since we already know roughly what it should be, based on our use of the normal distribution.  To get the 95% confidence interval, we find the points in the distribution of estimated values that correspond to the top and bottom 2.5% of values, using the quantile() function.

```{r}
mean_bootci=quantile(resampleMeans,c(0.025,0.975))
sampleMean=mean(NHANES_sample$Height)
sampleSE=sd(NHANES_sample$Height)/sqrt(sampSize)
mean_ci=c(sampleMean-sampleSE*1.96, sampleMean+sampleSE*1.96)

trimmedMean_bootci=quantile(resampleTrimmedMeans,c(0.025,0.975))

meanResults=as.data.frame(rbind(mean_ci,mean_bootci,trimmedMean_bootci))
names(meanResults)=c('lowerCI','upperCI')
meanResults$width=meanResults$upperCI - meanResults$lowerCI
meanResults$mean=c(sampleMean,mean(resampleMeans),mean(resampleTrimmedMeans))
meanResults=meanResults[,c('lowerCI','mean','upperCI','width')]
row.names(meanResults)=c('Mean (normal)','Mean (boostrap)','Trimmed mean (bootstrap)')
print(meanResults)
```

### Permutation testing 

NOTE: This material will be featured in a later lecture when we talk about statistical inference.

Now let's say that we want to determine whether there is really a difference in height between males and females, using our sample from the NHANES data.  First, let's use the same code we used in the last session, to see how the confidence intervals compare to one another.

```{r}
heightDf=group_by(NHANES_sample, Gender) %>% summarise(mean=mean(Height),sd=sd(Height),n=length(Height))
heightDf$se=heightDf$sd/sqrt(heightDf$n)
heightDf$lowerCI=heightDf$mean - heightDf$se*1.96
heightDf$upperCI=heightDf$mean + heightDf$se*1.96
print(heightDf)
```

Once again, we see that there is a large difference in height between males and females in our group.  

Now let's say that we would like to put a number on our confidence for *how different* these groups are.  The idea behind permutation testing is to generate a distribution of values that we would expect if there really was no difference between the groups, and then compare our observed difference to that distribution.  The way that we usually do this is to randomly shuffle (or *permute*) the labels for each individual; that is, we keep the overall distribution of heights the same, but we break the relationship between height and gender in the shuffled dataset, such that there should be no relationship between height and (shuffled) gender.  Let's see how this would work.

```{r}

trueMeanDiff=heightDf$mean[2] - heightDf$mean[1]
print(paste('mean difference in height in the sample:',trueMeanDiff))
NHANES_resample=NHANES_sample
NHANES_resample$Gender=sample(NHANES_resample$Gender)
print(paste('Proportion of subjects with the correct gender label in the resampled data:',sum(NHANES_resample$Gender==NHANES_sample$Gender)/sampSize))
resampDf=group_by(NHANES_resample, Gender) %>% summarise(mean=mean(Height))
resampMeanDiff=resampDf$mean[2] - resampDf$mean[1]
print(paste('mean difference in height in the resampled data:',resampMeanDiff))

```

Now let's do it a bunch of times, each time recording the mean difference.

```{r}
nResamples=5000

resampMeanDiff=array(NA,nResamples)
NHANES_resample=NHANES_sample

for (i in 1:nResamples){
  NHANES_resample$Gender=sample(NHANES_resample$Gender)
  resampDf=group_by(NHANES_resample, Gender) %>% summarise(mean=mean(Height))
  resampMeanDiff[i]=resampDf$mean[2] - resampDf$mean[1]
}
```

Now let's look at the distribution of differences in the resampled datasets.

```{r}
ggplot(data.frame(meanDiff=resampMeanDiff),aes(meanDiff)) +
  geom_vline(xintercept=trueMeanDiff,color='blue') + 
  geom_histogram(bins=100)
print(paste('Mean difference across all resamples:',mean(resampMeanDiff)))
```

Using these data, we can now ask how likely it would be for us to find a difference as big as the one in the real data, if the "null hypothesis" of no difference was really true (as we made it in the permuted data).

```{r}
print(paste('Number of',nResamples,'permutations with a difference greater than',format(trueMeanDiff,digits=4),'=',
            sum(trueMeanDiff<resampMeanDiff)))
```

This shows us that there is less than a 1/5000 chance of finding such a large difference between groups if the state of the world is that there is no difference.

Let's try it with another variable that we don't think should have an effect. Let's look at whether the person has ever reported to a health professional that they have trouble sleeping.

```{r}
nResamples=5000

resampMeanDiff=array(NA,nResamples)
NHANES_resample=NHANES_sample

for (i in 1:nResamples){
  NHANES_resample$SleepTrouble=sample(NHANES_resample$SleepTrouble)
  resampDf=group_by(NHANES_resample, SleepTrouble) %>% summarise(mean=mean(Height))
  resampMeanDiff[i]=resampDf$mean[2] - resampDf$mean[1]
}

sleepDf=group_by(NHANES_sample, SleepTrouble) %>% summarise(mean=mean(Height),sd=sd(Height),n=length(Height))
trueMeanDiff=sleepDf$mean[2] - sleepDf$mean[1]

print(paste('Number of',nResamples,'permutations with a difference greater than',format(trueMeanDiff,digits=4),'=',
            sum(trueMeanDiff<resampMeanDiff)))

```

